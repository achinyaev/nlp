{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-27T13:05:34.027814Z","iopub.execute_input":"2022-05-27T13:05:34.028233Z","iopub.status.idle":"2022-05-27T13:05:34.043891Z","shell.execute_reply.started":"2022-05-27T13:05:34.028198Z","shell.execute_reply":"2022-05-27T13:05:34.043198Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:34.217511Z","iopub.execute_input":"2022-05-27T13:05:34.217789Z","iopub.status.idle":"2022-05-27T13:05:36.991480Z","shell.execute_reply.started":"2022-05-27T13:05:34.217758Z","shell.execute_reply":"2022-05-27T13:05:36.990634Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/pushkin-stihi/pushkin_stihi2.txt'","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:36.994087Z","iopub.execute_input":"2022-05-27T13:05:36.994727Z","iopub.status.idle":"2022-05-27T13:05:36.998277Z","shell.execute_reply.started":"2022-05-27T13:05:36.994687Z","shell.execute_reply":"2022-05-27T13:05:36.997550Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"text = open(data_path, 'r', encoding='cp1251').read()\n# length of text is the number of characters in it\nprint('Length of text: {} characters'.format(len(text)))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:36.999961Z","iopub.execute_input":"2022-05-27T13:05:37.000506Z","iopub.status.idle":"2022-05-27T13:05:37.014324Z","shell.execute_reply.started":"2022-05-27T13:05:37.000470Z","shell.execute_reply":"2022-05-27T13:05:37.013348Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(text[:500])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:37.016176Z","iopub.execute_input":"2022-05-27T13:05:37.016662Z","iopub.status.idle":"2022-05-27T13:05:37.021007Z","shell.execute_reply.started":"2022-05-27T13:05:37.016627Z","shell.execute_reply":"2022-05-27T13:05:37.020225Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#словарь\n\nvocab = sorted(set(text))\nprint('{} unique characters'.format(len(vocab)))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:37.022257Z","iopub.execute_input":"2022-05-27T13:05:37.022838Z","iopub.status.idle":"2022-05-27T13:05:37.041968Z","shell.execute_reply.started":"2022-05-27T13:05:37.022799Z","shell.execute_reply":"2022-05-27T13:05:37.040939Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"char2idx = {u:i for i, u in enumerate(vocab)}\nidx2char = np.array(vocab)\n\ntext_as_int = np.array([char2idx[c] for c in text])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:37.043389Z","iopub.execute_input":"2022-05-27T13:05:37.043760Z","iopub.status.idle":"2022-05-27T13:05:37.096846Z","shell.execute_reply.started":"2022-05-27T13:05:37.043724Z","shell.execute_reply":"2022-05-27T13:05:37.096182Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# The maximum length sentence you want for a single input in characters\nseq_length = 100\nexamples_per_epoch = len(text)//(seq_length+1)\n\n# Create training examples / targets\nchar_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n\nfor i in char_dataset.take(10):\n    print(idx2char[i.numpy()])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:37.098897Z","iopub.execute_input":"2022-05-27T13:05:37.099479Z","iopub.status.idle":"2022-05-27T13:05:38.091668Z","shell.execute_reply.started":"2022-05-27T13:05:37.099418Z","shell.execute_reply":"2022-05-27T13:05:38.090825Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n\nfor item in sequences.take(5):\n    print(repr(''.join(idx2char[item.numpy()])))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:38.093050Z","iopub.execute_input":"2022-05-27T13:05:38.093585Z","iopub.status.idle":"2022-05-27T13:05:38.106699Z","shell.execute_reply.started":"2022-05-27T13:05:38.093545Z","shell.execute_reply":"2022-05-27T13:05:38.105816Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def split_input_target(chunk):\n    input_text = chunk[:-1]\n    target_text = chunk[1:]\n    return input_text, target_text\n\ndataset = sequences.map(split_input_target)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:38.107920Z","iopub.execute_input":"2022-05-27T13:05:38.108256Z","iopub.status.idle":"2022-05-27T13:05:38.163404Z","shell.execute_reply.started":"2022-05-27T13:05:38.108232Z","shell.execute_reply":"2022-05-27T13:05:38.162693Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for input_example, target_example in  dataset.take(1):\n    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:38.166773Z","iopub.execute_input":"2022-05-27T13:05:38.167025Z","iopub.status.idle":"2022-05-27T13:05:38.189132Z","shell.execute_reply.started":"2022-05-27T13:05:38.167001Z","shell.execute_reply":"2022-05-27T13:05:38.188338Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Batch size\nBATCH_SIZE = 64\n\n# Buffer size to shuffle the dataset\n# (TF data is designed to work with possibly infinite sequences,\n# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n# it maintains a buffer in which it shuffles elements).\nBUFFER_SIZE = 10000\n\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n\n# Length of the vocabulary in chars\nvocab_size = len(vocab)\n\n# The embedding dimension\nembedding_dim = 128\n\n# Number of RNN units\nrnn_units = 1024","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:38.190450Z","iopub.execute_input":"2022-05-27T13:05:38.190967Z","iopub.status.idle":"2022-05-27T13:05:38.198586Z","shell.execute_reply.started":"2022-05-27T13:05:38.190932Z","shell.execute_reply":"2022-05-27T13:05:38.197806Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                                  batch_input_shape=[batch_size, None]),\n                                 \n        tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n\n        tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n\n         tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n        \n        tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n                                   \n        tf.keras.layers.Dense(vocab_size)\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:38.199739Z","iopub.execute_input":"2022-05-27T13:05:38.200398Z","iopub.status.idle":"2022-05-27T13:05:38.209230Z","shell.execute_reply.started":"2022-05-27T13:05:38.200362Z","shell.execute_reply":"2022-05-27T13:05:38.208371Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = build_model(\n    vocab_size=len(vocab),\n    embedding_dim=embedding_dim,\n    rnn_units=rnn_units,\n    batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:38.210460Z","iopub.execute_input":"2022-05-27T13:05:38.210849Z","iopub.status.idle":"2022-05-27T13:05:39.157719Z","shell.execute_reply.started":"2022-05-27T13:05:38.210813Z","shell.execute_reply":"2022-05-27T13:05:39.156916Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for input_example_batch, target_example_batch in dataset.take(1):\n    example_batch_predictions = model(input_example_batch)\n    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:39.160733Z","iopub.execute_input":"2022-05-27T13:05:39.161010Z","iopub.status.idle":"2022-05-27T13:05:40.186643Z","shell.execute_reply.started":"2022-05-27T13:05:39.160984Z","shell.execute_reply":"2022-05-27T13:05:40.185816Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.188075Z","iopub.execute_input":"2022-05-27T13:05:40.188478Z","iopub.status.idle":"2022-05-27T13:05:40.194548Z","shell.execute_reply.started":"2022-05-27T13:05:40.188439Z","shell.execute_reply":"2022-05-27T13:05:40.193603Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"example_batch_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.195984Z","iopub.execute_input":"2022-05-27T13:05:40.196420Z","iopub.status.idle":"2022-05-27T13:05:40.210603Z","shell.execute_reply.started":"2022-05-27T13:05:40.196379Z","shell.execute_reply":"2022-05-27T13:05:40.209834Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.211553Z","iopub.execute_input":"2022-05-27T13:05:40.213379Z","iopub.status.idle":"2022-05-27T13:05:40.219183Z","shell.execute_reply.started":"2022-05-27T13:05:40.213341Z","shell.execute_reply":"2022-05-27T13:05:40.218328Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\nprint()\nprint(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.220735Z","iopub.execute_input":"2022-05-27T13:05:40.221412Z","iopub.status.idle":"2022-05-27T13:05:40.228795Z","shell.execute_reply.started":"2022-05-27T13:05:40.221256Z","shell.execute_reply":"2022-05-27T13:05:40.227837Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def loss(labels, logits):\n    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n\nexample_batch_loss = loss(target_example_batch, example_batch_predictions)\nprint(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\nprint(\"scalar_loss:      \", example_batch_loss.numpy().mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.230378Z","iopub.execute_input":"2022-05-27T13:05:40.231093Z","iopub.status.idle":"2022-05-27T13:05:40.242673Z","shell.execute_reply.started":"2022-05-27T13:05:40.231056Z","shell.execute_reply":"2022-05-27T13:05:40.241724Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=loss)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.244097Z","iopub.execute_input":"2022-05-27T13:05:40.244512Z","iopub.status.idle":"2022-05-27T13:05:40.258147Z","shell.execute_reply.started":"2022-05-27T13:05:40.244476Z","shell.execute_reply":"2022-05-27T13:05:40.257195Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#!mkdir ./training_checkpoints","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.259580Z","iopub.execute_input":"2022-05-27T13:05:40.260306Z","iopub.status.idle":"2022-05-27T13:05:40.264394Z","shell.execute_reply.started":"2022-05-27T13:05:40.260268Z","shell.execute_reply":"2022-05-27T13:05:40.263542Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Directory where the checkpoints will be saved\n#checkpoint_dir = 'training_checkpoints_gru' # Сохраняем результаты сети с GRU\ncheckpoint_dir = './training_checkpoints' # Сохраняем результату сети с LSTM\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_freq=88*3,\n    save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.266026Z","iopub.execute_input":"2022-05-27T13:05:40.266732Z","iopub.status.idle":"2022-05-27T13:05:40.273283Z","shell.execute_reply.started":"2022-05-27T13:05:40.266693Z","shell.execute_reply":"2022-05-27T13:05:40.272525Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"checkpoint_prefix","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.274766Z","iopub.execute_input":"2022-05-27T13:05:40.275300Z","iopub.status.idle":"2022-05-27T13:05:40.283321Z","shell.execute_reply.started":"2022-05-27T13:05:40.275264Z","shell.execute_reply":"2022-05-27T13:05:40.282322Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 200","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.284708Z","iopub.execute_input":"2022-05-27T13:05:40.285740Z","iopub.status.idle":"2022-05-27T13:05:40.291831Z","shell.execute_reply.started":"2022-05-27T13:05:40.285697Z","shell.execute_reply":"2022-05-27T13:05:40.290209Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:05:40.293661Z","iopub.execute_input":"2022-05-27T13:05:40.294714Z","iopub.status.idle":"2022-05-27T13:35:39.833514Z","shell.execute_reply.started":"2022-05-27T13:05:40.294672Z","shell.execute_reply":"2022-05-27T13:35:39.832744Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tf.train.latest_checkpoint(checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:35:39.835056Z","iopub.execute_input":"2022-05-27T13:35:39.836282Z","iopub.status.idle":"2022-05-27T13:35:39.847534Z","shell.execute_reply.started":"2022-05-27T13:35:39.836242Z","shell.execute_reply":"2022-05-27T13:35:39.846738Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:35:39.854690Z","iopub.execute_input":"2022-05-27T13:35:39.855515Z","iopub.status.idle":"2022-05-27T13:35:39.863173Z","shell.execute_reply.started":"2022-05-27T13:35:39.855479Z","shell.execute_reply":"2022-05-27T13:35:39.862049Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def generate_text(model, start_string):\n    # Evaluation step (generating text using the learned model)\n\n    # Number of characters to generate\n    num_generate = 75\n\n    # Converting our start string to numbers (vectorizing)\n    input_eval = [char2idx[s] for s in start_string]\n    input_eval = tf.expand_dims(input_eval, 0)\n\n    # Empty string to store our results\n    text_generated = []\n\n    # Low temperature results in more predictable text.\n    # Higher temperature results in more surprising text.\n    # Experiment to find the best setting.\n    temperature = 0.5\n\n    # Here batch size == 1\n    model.reset_states()\n    for i in range(num_generate):\n        predictions = model(input_eval)\n        predictions = tf.squeeze(predictions, 0)\n        # using a categorical distribution to predict the character returned by the model\n        predictions = predictions / temperature\n        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n\n        # Pass the predicted character as the next input to the model\n        # along with the previous hidden state\n        input_eval = tf.expand_dims([predicted_id], 0)\n\n        text_generated.append(idx2char[predicted_id])\n\n    return (start_string + ''.join(text_generated))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:46:41.947035Z","iopub.execute_input":"2022-05-27T13:46:41.948015Z","iopub.status.idle":"2022-05-27T13:46:41.955119Z","shell.execute_reply.started":"2022-05-27T13:46:41.947974Z","shell.execute_reply":"2022-05-27T13:46:41.954372Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\nmodel.build(tf.TensorShape([1, None]))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:35:39.901453Z","iopub.execute_input":"2022-05-27T13:35:39.902107Z","iopub.status.idle":"2022-05-27T13:35:40.845747Z","shell.execute_reply.started":"2022-05-27T13:35:39.902071Z","shell.execute_reply":"2022-05-27T13:35:40.844885Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:35:40.847047Z","iopub.execute_input":"2022-05-27T13:35:40.847419Z","iopub.status.idle":"2022-05-27T13:35:40.854778Z","shell.execute_reply.started":"2022-05-27T13:35:40.847384Z","shell.execute_reply":"2022-05-27T13:35:40.852912Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"text_ = generate_text(model, start_string=u\"Кто я? Что я? Только лишь \")\nprint(f'Текст после {EPOCHS} эпох\\n')\nprint(text_)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:49:14.165710Z","iopub.execute_input":"2022-05-27T13:49:14.166082Z","iopub.status.idle":"2022-05-27T13:49:15.028681Z","shell.execute_reply.started":"2022-05-27T13:49:14.166051Z","shell.execute_reply":"2022-05-27T13:49:15.027832Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"text_ = generate_text(model, start_string=u\"Ну, целуй меня, \")\nprint(f'Текст после {EPOCHS} эпох\\n')\nprint(text_)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:48:07.424216Z","iopub.execute_input":"2022-05-27T13:48:07.424587Z","iopub.status.idle":"2022-05-27T13:48:08.294413Z","shell.execute_reply.started":"2022-05-27T13:48:07.424556Z","shell.execute_reply":"2022-05-27T13:48:08.293576Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"text_ = generate_text(model, start_string=u\"Гой ты, Русь, моя \")\nprint(f'Текст после {EPOCHS} эпох\\n')\nprint(text_)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:52:59.605411Z","iopub.execute_input":"2022-05-27T13:52:59.605766Z","iopub.status.idle":"2022-05-27T13:53:00.488870Z","shell.execute_reply.started":"2022-05-27T13:52:59.605734Z","shell.execute_reply":"2022-05-27T13:53:00.488066Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"**Функция потерь снижается на каждой эпохе, можно обучать и дальше, если есть время.**","metadata":{}}]}