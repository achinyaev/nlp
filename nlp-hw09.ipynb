{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-27T12:24:49.978719Z","iopub.execute_input":"2022-05-27T12:24:49.979069Z","iopub.status.idle":"2022-05-27T12:24:49.987079Z","shell.execute_reply.started":"2022-05-27T12:24:49.979039Z","shell.execute_reply":"2022-05-27T12:24:49.986061Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.144339Z","iopub.execute_input":"2022-05-27T12:24:50.145006Z","iopub.status.idle":"2022-05-27T12:24:50.149001Z","shell.execute_reply.started":"2022-05-27T12:24:50.144970Z","shell.execute_reply":"2022-05-27T12:24:50.148184Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/pushkin-stihi/pushkin_stihi2.txt'","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.289274Z","iopub.execute_input":"2022-05-27T12:24:50.289927Z","iopub.status.idle":"2022-05-27T12:24:50.293753Z","shell.execute_reply.started":"2022-05-27T12:24:50.289896Z","shell.execute_reply":"2022-05-27T12:24:50.292445Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"text = open(data_path, 'r', encoding='cp1251').read()\n# length of text is the number of characters in it\nprint('Length of text: {} characters'.format(len(text)))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.454051Z","iopub.execute_input":"2022-05-27T12:24:50.454647Z","iopub.status.idle":"2022-05-27T12:24:50.463603Z","shell.execute_reply.started":"2022-05-27T12:24:50.454613Z","shell.execute_reply":"2022-05-27T12:24:50.462866Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(text[:500])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.537373Z","iopub.execute_input":"2022-05-27T12:24:50.537666Z","iopub.status.idle":"2022-05-27T12:24:50.541935Z","shell.execute_reply.started":"2022-05-27T12:24:50.537633Z","shell.execute_reply":"2022-05-27T12:24:50.541136Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#словарь\n\nvocab = sorted(set(text))\nprint('{} unique characters'.format(len(vocab)))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.634358Z","iopub.execute_input":"2022-05-27T12:24:50.634740Z","iopub.status.idle":"2022-05-27T12:24:50.650883Z","shell.execute_reply.started":"2022-05-27T12:24:50.634712Z","shell.execute_reply":"2022-05-27T12:24:50.649947Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"char2idx = {u:i for i, u in enumerate(vocab)}\nidx2char = np.array(vocab)\n\ntext_as_int = np.array([char2idx[c] for c in text])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.722296Z","iopub.execute_input":"2022-05-27T12:24:50.722798Z","iopub.status.idle":"2022-05-27T12:24:50.775061Z","shell.execute_reply.started":"2022-05-27T12:24:50.722770Z","shell.execute_reply":"2022-05-27T12:24:50.774360Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# The maximum length sentence you want for a single input in characters\nseq_length = 100\nexamples_per_epoch = len(text)//(seq_length+1)\n\n# Create training examples / targets\nchar_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n\nfor i in char_dataset.take(10):\n    print(idx2char[i.numpy()])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.832563Z","iopub.execute_input":"2022-05-27T12:24:50.832854Z","iopub.status.idle":"2022-05-27T12:24:50.847103Z","shell.execute_reply.started":"2022-05-27T12:24:50.832828Z","shell.execute_reply":"2022-05-27T12:24:50.846322Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n\nfor item in sequences.take(5):\n    print(repr(''.join(idx2char[item.numpy()])))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:50.907818Z","iopub.execute_input":"2022-05-27T12:24:50.908217Z","iopub.status.idle":"2022-05-27T12:24:50.924572Z","shell.execute_reply.started":"2022-05-27T12:24:50.908190Z","shell.execute_reply":"2022-05-27T12:24:50.923838Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def split_input_target(chunk):\n    input_text = chunk[:-1]\n    target_text = chunk[1:]\n    return input_text, target_text\n\ndataset = sequences.map(split_input_target)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:51.002459Z","iopub.execute_input":"2022-05-27T12:24:51.002781Z","iopub.status.idle":"2022-05-27T12:24:51.019539Z","shell.execute_reply.started":"2022-05-27T12:24:51.002753Z","shell.execute_reply":"2022-05-27T12:24:51.018793Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for input_example, target_example in  dataset.take(1):\n    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:51.101362Z","iopub.execute_input":"2022-05-27T12:24:51.101909Z","iopub.status.idle":"2022-05-27T12:24:51.121611Z","shell.execute_reply.started":"2022-05-27T12:24:51.101876Z","shell.execute_reply":"2022-05-27T12:24:51.120808Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Batch size\nBATCH_SIZE = 64\n\n# Buffer size to shuffle the dataset\n# (TF data is designed to work with possibly infinite sequences,\n# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n# it maintains a buffer in which it shuffles elements).\nBUFFER_SIZE = 10000\n\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n\n# Length of the vocabulary in chars\nvocab_size = len(vocab)\n\n# The embedding dimension\nembedding_dim = 128\n\n# Number of RNN units\nrnn_units = 1024","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:51.223546Z","iopub.execute_input":"2022-05-27T12:24:51.224251Z","iopub.status.idle":"2022-05-27T12:24:51.230538Z","shell.execute_reply.started":"2022-05-27T12:24:51.224221Z","shell.execute_reply":"2022-05-27T12:24:51.229711Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                                  batch_input_shape=[batch_size, None]),\n                                 \n        tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n\n        tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n\n         tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n        \n        tf.keras.layers.LSTM(rnn_units,\n                            return_sequences=True,\n                            stateful=True,\n                            recurrent_initializer='glorot_uniform'),\n                                   \n        tf.keras.layers.Dense(vocab_size)\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:51.247323Z","iopub.execute_input":"2022-05-27T12:24:51.247694Z","iopub.status.idle":"2022-05-27T12:24:51.255135Z","shell.execute_reply.started":"2022-05-27T12:24:51.247667Z","shell.execute_reply":"2022-05-27T12:24:51.254216Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model = build_model(\n    vocab_size=len(vocab),\n    embedding_dim=embedding_dim,\n    rnn_units=rnn_units,\n    batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:51.301301Z","iopub.execute_input":"2022-05-27T12:24:51.301761Z","iopub.status.idle":"2022-05-27T12:24:52.255204Z","shell.execute_reply.started":"2022-05-27T12:24:51.301732Z","shell.execute_reply":"2022-05-27T12:24:52.253333Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"for input_example_batch, target_example_batch in dataset.take(1):\n    example_batch_predictions = model(input_example_batch)\n    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:52.259544Z","iopub.execute_input":"2022-05-27T12:24:52.260405Z","iopub.status.idle":"2022-05-27T12:24:53.542879Z","shell.execute_reply.started":"2022-05-27T12:24:52.260362Z","shell.execute_reply":"2022-05-27T12:24:53.542049Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.544102Z","iopub.execute_input":"2022-05-27T12:24:53.545115Z","iopub.status.idle":"2022-05-27T12:24:53.556656Z","shell.execute_reply.started":"2022-05-27T12:24:53.545078Z","shell.execute_reply":"2022-05-27T12:24:53.554953Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"example_batch_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.561642Z","iopub.execute_input":"2022-05-27T12:24:53.562363Z","iopub.status.idle":"2022-05-27T12:24:53.584642Z","shell.execute_reply.started":"2022-05-27T12:24:53.562321Z","shell.execute_reply":"2022-05-27T12:24:53.582211Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.585937Z","iopub.execute_input":"2022-05-27T12:24:53.586457Z","iopub.status.idle":"2022-05-27T12:24:53.600972Z","shell.execute_reply.started":"2022-05-27T12:24:53.586420Z","shell.execute_reply":"2022-05-27T12:24:53.599883Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\nprint()\nprint(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.603696Z","iopub.execute_input":"2022-05-27T12:24:53.606134Z","iopub.status.idle":"2022-05-27T12:24:53.618088Z","shell.execute_reply.started":"2022-05-27T12:24:53.606099Z","shell.execute_reply":"2022-05-27T12:24:53.617077Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def loss(labels, logits):\n    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n\nexample_batch_loss = loss(target_example_batch, example_batch_predictions)\nprint(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\nprint(\"scalar_loss:      \", example_batch_loss.numpy().mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.621807Z","iopub.execute_input":"2022-05-27T12:24:53.622698Z","iopub.status.idle":"2022-05-27T12:24:53.638420Z","shell.execute_reply.started":"2022-05-27T12:24:53.622639Z","shell.execute_reply":"2022-05-27T12:24:53.637197Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=loss)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.639936Z","iopub.execute_input":"2022-05-27T12:24:53.640702Z","iopub.status.idle":"2022-05-27T12:24:53.653727Z","shell.execute_reply.started":"2022-05-27T12:24:53.640659Z","shell.execute_reply":"2022-05-27T12:24:53.652940Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#!mkdir ./training_checkpoints","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.655398Z","iopub.execute_input":"2022-05-27T12:24:53.655819Z","iopub.status.idle":"2022-05-27T12:24:53.659938Z","shell.execute_reply.started":"2022-05-27T12:24:53.655780Z","shell.execute_reply":"2022-05-27T12:24:53.659173Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Directory where the checkpoints will be saved\n#checkpoint_dir = 'training_checkpoints_gru' # Сохраняем результаты сети с GRU\ncheckpoint_dir = './training_checkpoints' # Сохраняем результату сети с LSTM\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ncheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_freq=88*3,\n    save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.663399Z","iopub.execute_input":"2022-05-27T12:24:53.664116Z","iopub.status.idle":"2022-05-27T12:24:53.671065Z","shell.execute_reply.started":"2022-05-27T12:24:53.664074Z","shell.execute_reply":"2022-05-27T12:24:53.669998Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"checkpoint_prefix","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.672677Z","iopub.execute_input":"2022-05-27T12:24:53.673217Z","iopub.status.idle":"2022-05-27T12:24:53.681733Z","shell.execute_reply.started":"2022-05-27T12:24:53.673118Z","shell.execute_reply":"2022-05-27T12:24:53.680663Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 200","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.683487Z","iopub.execute_input":"2022-05-27T12:24:53.683903Z","iopub.status.idle":"2022-05-27T12:24:53.689297Z","shell.execute_reply.started":"2022-05-27T12:24:53.683865Z","shell.execute_reply":"2022-05-27T12:24:53.687817Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:24:53.691287Z","iopub.execute_input":"2022-05-27T12:24:53.691900Z","iopub.status.idle":"2022-05-27T12:40:11.643846Z","shell.execute_reply.started":"2022-05-27T12:24:53.691858Z","shell.execute_reply":"2022-05-27T12:40:11.642988Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"tf.train.latest_checkpoint(checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:40:11.645290Z","iopub.execute_input":"2022-05-27T12:40:11.645662Z","iopub.status.idle":"2022-05-27T12:40:11.653845Z","shell.execute_reply.started":"2022-05-27T12:40:11.645624Z","shell.execute_reply":"2022-05-27T12:40:11.653173Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:40:11.655028Z","iopub.execute_input":"2022-05-27T12:40:11.655517Z","iopub.status.idle":"2022-05-27T12:40:11.665282Z","shell.execute_reply.started":"2022-05-27T12:40:11.655481Z","shell.execute_reply":"2022-05-27T12:40:11.664529Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def generate_text(model, start_string):\n    # Evaluation step (generating text using the learned model)\n\n    # Number of characters to generate\n    num_generate = 500\n\n    # Converting our start string to numbers (vectorizing)\n    input_eval = [char2idx[s] for s in start_string]\n    input_eval = tf.expand_dims(input_eval, 0)\n\n    # Empty string to store our results\n    text_generated = []\n\n    # Low temperature results in more predictable text.\n    # Higher temperature results in more surprising text.\n    # Experiment to find the best setting.\n    temperature = 0.5\n\n    # Here batch size == 1\n    model.reset_states()\n    for i in range(num_generate):\n        predictions = model(input_eval)\n        predictions = tf.squeeze(predictions, 0)\n        # using a categorical distribution to predict the character returned by the model\n        predictions = predictions / temperature\n        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n\n        # Pass the predicted character as the next input to the model\n        # along with the previous hidden state\n        input_eval = tf.expand_dims([predicted_id], 0)\n\n        text_generated.append(idx2char[predicted_id])\n\n    return (start_string + ''.join(text_generated))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:40:11.666473Z","iopub.execute_input":"2022-05-27T12:40:11.667325Z","iopub.status.idle":"2022-05-27T12:40:11.676285Z","shell.execute_reply.started":"2022-05-27T12:40:11.667289Z","shell.execute_reply":"2022-05-27T12:40:11.675400Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"input_eval = [char2idx[s] for s in \"Мама мыла раму \"]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:57:53.669696Z","iopub.execute_input":"2022-05-27T12:57:53.670053Z","iopub.status.idle":"2022-05-27T12:57:53.674512Z","shell.execute_reply.started":"2022-05-27T12:57:53.670024Z","shell.execute_reply":"2022-05-27T12:57:53.673656Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\nmodel.build(tf.TensorShape([1, None]))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:03:00.753097Z","iopub.execute_input":"2022-05-27T13:03:00.753702Z","iopub.status.idle":"2022-05-27T13:03:01.858342Z","shell.execute_reply.started":"2022-05-27T13:03:00.753660Z","shell.execute_reply":"2022-05-27T13:03:01.857447Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:03:11.432021Z","iopub.execute_input":"2022-05-27T13:03:11.432632Z","iopub.status.idle":"2022-05-27T13:03:11.439028Z","shell.execute_reply.started":"2022-05-27T13:03:11.432596Z","shell.execute_reply":"2022-05-27T13:03:11.438045Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"text_ = generate_text(model, start_string=u\"Мама мыла раму \")\nprint(f'Текст после {EPOCHS} эпох')\nprint(text_)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:03:28.559542Z","iopub.execute_input":"2022-05-27T13:03:28.560121Z","iopub.status.idle":"2022-05-27T13:03:34.398565Z","shell.execute_reply.started":"2022-05-27T13:03:28.560084Z","shell.execute_reply":"2022-05-27T13:03:34.397720Z"},"trusted":true},"execution_count":71,"outputs":[]}]}